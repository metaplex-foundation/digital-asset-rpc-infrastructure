use crate::common::Network;
use crate::common::TestSetup;
use crate::common::TestSetupOptions;
use borsh::BorshSerialize;
use bubblegum_batch_sdk::batch_mint_client::BatchMintClient;
use bubblegum_batch_sdk::batch_mint_validations::generate_batch_mint;
use bubblegum_batch_sdk::model::BatchMint;
use bubblegum_batch_sdk::model::CollectionConfig;
use cadence::{NopMetricSink, StatsdClient};
use cadence_macros::set_global_default;
use das_api::api::ApiContract;
use das_api::api::GetAssetProof;
use digital_asset_types::dao::asset;
use digital_asset_types::dao::sea_orm_active_enums::{
    BatchMintFailStatus, BatchMintPersistingState,
};
use digital_asset_types::dao::{batch_mint, batch_mint_to_verify};
use flatbuffers::FlatBufferBuilder;
use mpl_bubblegum::types::Collection;
use mpl_bubblegum::types::Creator;
use mpl_bubblegum::types::TokenProgramVersion;
use mpl_bubblegum::types::Version;
use mpl_bubblegum::types::{LeafSchema, MetadataArgs};
use mpl_bubblegum::utils::get_asset_id;
use mpl_bubblegum::LeafSchemaEvent;
use nft_ingester::batch_mint_updates::create_batch_mint_notification_channel;
use nft_ingester::plerkle::PlerkleTransactionInfo;
use plerkle_serialization::root_as_transaction_info;
use plerkle_serialization::serializer::serialize_transaction;
use program_transformers::batch_minting::batch_mint_persister::{
    BatchMintPersister, MockBatchMintDownloader,
};
use program_transformers::error::BatchMintValidationError;
use program_transformers::ProgramTransformer;
use sea_orm::sea_query::OnConflict;
use sea_orm::{ColumnTrait, ConnectionTrait, DbBackend, IntoActiveModel, QueryTrait, Set};
use sea_orm::{EntityTrait, QueryFilter};
use solana_client::nonblocking::rpc_client::RpcClient;
use solana_sdk::instruction::CompiledInstruction;
use solana_sdk::keccak;
use solana_sdk::message::{Message, MessageHeader};
use solana_sdk::pubkey::Pubkey;
use solana_sdk::signature::Keypair;
use solana_sdk::signature::Signature;
use solana_sdk::signer::Signer;
use solana_sdk::transaction::{SanitizedTransaction, Transaction};
use solana_transaction_status::{InnerInstruction, InnerInstructions, TransactionStatusMeta};
use spl_account_compression::events::ApplicationDataEvent;
use spl_account_compression::events::ApplicationDataEventV1;
use spl_account_compression::events::ChangeLogEventV1;
use spl_account_compression::state::PathNode;
use spl_account_compression::AccountCompressionEvent;
use spl_account_compression::ChangeLogEvent;
use spl_concurrent_merkle_tree::concurrent_merkle_tree::ConcurrentMerkleTree;
use std::collections::HashMap;
use std::fs::File;
use std::str::FromStr;
use std::sync::Arc;
use std::time::Duration;
use tokio::task::JoinSet;

#[tokio::test]
async fn save_batch_mint_to_queue_test() {
    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new("save_batch_mint_to_queue_test".to_string()).await;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();

    // arbitrary data
    let batch_mint_instruction_data =
        mpl_bubblegum::instructions::FinalizeTreeWithRootInstructionArgs {
            root: [1; 32],
            rightmost_leaf: [1; 32],
            rightmost_index: 99,
            metadata_url: metadata_url.clone(),
            metadata_hash: metadata_hash.clone(),
        };

    // took it from Bubblegum client
    // this value is generated by Anchor library, it's instruction identifier
    let mut instruction_data = vec![77, 73, 220, 153, 126, 225, 64, 204];
    instruction_data.extend(batch_mint_instruction_data.try_to_vec().unwrap().iter());

    let transaction = SanitizedTransaction::from_transaction_for_tests(Transaction {
        signatures: vec![Signature::new_unique()],
        message: Message {
            header: MessageHeader {
                num_required_signatures: 1,
                num_readonly_signed_accounts: 0,
                num_readonly_unsigned_accounts: 0,
            },
            account_keys: vec![
                Pubkey::new_unique(),
                Pubkey::from_str("BGUMAp9Gq7iTEuizy4pqaxsTyUCBK68MDfK752saRPUY").unwrap(),
                Pubkey::new_unique(),
                Pubkey::new_unique(),
                Pubkey::new_unique(),
                Pubkey::new_unique(),
            ],
            recent_blockhash: [1; 32].into(),
            instructions: vec![CompiledInstruction {
                program_id_index: 1,
                accounts: vec![0, 4, 2, 3, 5],
                data: instruction_data,
            }],
        },
    });

    // inner instruction is useless here but required by transaction parser
    let transaction_status_meta = TransactionStatusMeta {
        inner_instructions: Some(vec![InnerInstructions {
            index: 0,
            instructions: vec![InnerInstruction {
                instruction: CompiledInstruction {
                    program_id_index: 2,
                    accounts: vec![],
                    data: vec![],
                },
                stack_height: None,
            }],
        }]),
        ..Default::default()
    };

    let transaction_info =
        plerkle_serialization::solana_geyser_plugin_interface_shims::ReplicaTransactionInfoV2 {
            signature: &Signature::new_unique(),
            is_vote: false,
            transaction: &transaction,
            transaction_status_meta: &transaction_status_meta,
            index: 0,
        };
    let builder = FlatBufferBuilder::new();
    let builder = serialize_transaction(builder, &transaction_info, 10);
    let transaction_info = PlerkleTransactionInfo(
        root_as_transaction_info(builder.finished_data().to_vec().as_slice()).unwrap(),
    )
    .try_into()
    .unwrap();

    setup
        .transformer
        .handle_transaction(&transaction_info)
        .await
        .unwrap();

    let r = batch_mint_to_verify::Entity::find()
        .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
        .one(setup.db.as_ref())
        .await
        .unwrap()
        .unwrap();

    assert_eq!(r.file_hash, metadata_hash);
    assert_eq!(r.url, metadata_url);
}

#[tokio::test]
async fn skip_batched_minted_trees_test() {
    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new_with_options(
        "skip_batched_minted_trees_test".to_string(),
        TestSetupOptions {
            network: Some(Network::Devnet),
            skip_batch_minted_trees: false,
        },
    )
    .await;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();

    // arbitrary data
    let batch_mint_instruction_data =
        mpl_bubblegum::instructions::FinalizeTreeWithRootInstructionArgs {
            root: [1; 32],
            rightmost_leaf: [1; 32],
            rightmost_index: 99,
            metadata_url: metadata_url.clone(),
            metadata_hash: metadata_hash.clone(),
        };

    // took it from Bubblegum client
    // this value is generated by Anchor library, it's instruction identifier
    let mut instruction_data = vec![77, 73, 220, 153, 126, 225, 64, 204];
    instruction_data.extend(batch_mint_instruction_data.try_to_vec().unwrap().iter());

    let merkle_tree_id = Pubkey::new_unique();

    let transaction = SanitizedTransaction::from_transaction_for_tests(Transaction {
        signatures: vec![Signature::new_unique()],
        message: Message {
            header: MessageHeader {
                num_required_signatures: 1,
                num_readonly_signed_accounts: 0,
                num_readonly_unsigned_accounts: 0,
            },
            account_keys: vec![
                Pubkey::new_unique(),
                Pubkey::from_str("BGUMAp9Gq7iTEuizy4pqaxsTyUCBK68MDfK752saRPUY").unwrap(),
                Pubkey::new_unique(),
                Pubkey::new_unique(),
                merkle_tree_id,
                Pubkey::new_unique(),
            ],
            recent_blockhash: [1; 32].into(),
            instructions: vec![CompiledInstruction {
                program_id_index: 1,
                // here important only 1th index - 4
                accounts: vec![0, 4, 2, 3, 5],
                data: instruction_data,
            }],
        },
    });

    // inner instruction is useless here but required by transaction parser
    let transaction_status_meta = TransactionStatusMeta {
        inner_instructions: Some(vec![InnerInstructions {
            index: 0,
            instructions: vec![InnerInstruction {
                instruction: CompiledInstruction {
                    program_id_index: 2,
                    accounts: vec![],
                    data: vec![],
                },
                stack_height: None,
            }],
        }]),
        ..Default::default()
    };

    let transaction_info =
        plerkle_serialization::solana_geyser_plugin_interface_shims::ReplicaTransactionInfoV2 {
            signature: &Signature::new_unique(),
            is_vote: false,
            transaction: &transaction,
            transaction_status_meta: &transaction_status_meta,
            index: 0,
        };
    let builder = FlatBufferBuilder::new();
    let builder = serialize_transaction(builder, &transaction_info, 10);
    let transaction_info = PlerkleTransactionInfo(
        root_as_transaction_info(builder.finished_data().to_vec().as_slice()).unwrap(),
    )
    .try_into()
    .unwrap();

    setup
        .transformer
        .handle_transaction(&transaction_info)
        .await
        .unwrap();

    // mint asset and make sure we save it because program transformer is configured
    // to save batched minted updates
    mint_asset_to_tree(merkle_tree_id, &setup.transformer, 1, 1).await;

    let assets = asset::Entity::find().all(setup.db.as_ref()).await.unwrap();

    assert_eq!(assets.len(), 1);

    // now we change program transformer and tell it not to save updates related to batched minted trees
    // at this moment there is only 1 such tree
    // also we make sure that during initialization program transformer selects all the batched tree ids from the DB
    let setup = TestSetup::new_with_options(
        "skip_batched_minted_trees_test".to_string(),
        TestSetupOptions {
            network: Some(Network::Devnet),
            skip_batch_minted_trees: true,
        },
    )
    .await;

    mint_asset_to_tree(merkle_tree_id, &setup.transformer, 2, 2).await;

    let assets = asset::Entity::find().all(setup.db.as_ref()).await.unwrap();

    assert_eq!(assets.len(), 1);

    // now we switch back to saving batched mint tree updates and check if it works
    let setup = TestSetup::new_with_options(
        "skip_batched_minted_trees_test".to_string(),
        TestSetupOptions {
            network: Some(Network::Devnet),
            skip_batch_minted_trees: false,
        },
    )
    .await;

    mint_asset_to_tree(merkle_tree_id, &setup.transformer, 3, 3).await;

    let assets = asset::Entity::find().all(setup.db.as_ref()).await.unwrap();

    assert_eq!(assets.len(), 2);
}

async fn mint_asset_to_tree(
    merkle_tree: Pubkey,
    transformer: &ProgramTransformer,
    index: u64,
    sequence: u64,
) {
    let mint_instruction_data = mpl_bubblegum::instructions::MintV1InstructionArgs {
        metadata: MetadataArgs {
            name: "name".to_string(),
            symbol: "symbol".to_string(),
            uri: "uri".to_string(),
            seller_fee_basis_points: 1,
            primary_sale_happened: false,
            is_mutable: false,
            edition_nonce: None,
            token_standard: None,
            collection: None,
            uses: None,
            token_program_version: TokenProgramVersion::Original,
            creators: vec![],
        },
    };

    // took it from Bubblegum client
    // this value is generated by Anchor library, it's instruction identifier
    let mut instruction_data = vec![145, 98, 192, 118, 184, 147, 118, 104];
    instruction_data.extend(mint_instruction_data.try_to_vec().unwrap().iter());

    let transaction = SanitizedTransaction::from_transaction_for_tests(Transaction {
        signatures: vec![Signature::new_unique()],
        message: Message {
            header: MessageHeader {
                num_required_signatures: 1,
                num_readonly_signed_accounts: 0,
                num_readonly_unsigned_accounts: 0,
            },
            account_keys: vec![
                Pubkey::new_unique(),
                Pubkey::from_str("BGUMAp9Gq7iTEuizy4pqaxsTyUCBK68MDfK752saRPUY").unwrap(),
                Pubkey::from_str("noopb9bkMVfRPU8AsbpTUg8AQkHtKwMYZiFUjNRtMmV").unwrap(),
                Pubkey::new_unique(),
                merkle_tree,
                Pubkey::new_unique(),
            ],
            recent_blockhash: [1; 32].into(),
            instructions: vec![CompiledInstruction {
                program_id_index: 1,
                // here important only 3th index - 4
                accounts: vec![0, 3, 2, 4, 5],
                data: instruction_data,
            }],
        },
    });

    let change_log = ChangeLogEventV1 {
        id: merkle_tree,
        path: vec![
            PathNode {
                node: Pubkey::new_unique().to_bytes(),
                index: 32,
            },
            PathNode {
                node: Pubkey::new_unique().to_bytes(),
                index: 16,
            },
            PathNode {
                node: Pubkey::new_unique().to_bytes(),
                index: 8,
            },
            PathNode {
                node: Pubkey::new_unique().to_bytes(),
                index: 4,
            },
            PathNode {
                node: Pubkey::new_unique().to_bytes(),
                index: 2,
            },
            PathNode {
                node: Pubkey::new_unique().to_bytes(),
                index: 1,
            },
        ],
        seq: sequence,
        index: index as u32,
    };

    let change_log_event = AccountCompressionEvent::ChangeLog(ChangeLogEvent::V1(change_log));

    let leaf_schema = LeafSchemaEvent::new(
        Version::V1,
        LeafSchema::V1 {
            id: get_asset_id(&merkle_tree, index),
            owner: Pubkey::new_unique(),
            delegate: Pubkey::new_unique(),
            nonce: index,
            data_hash: Pubkey::new_unique().to_bytes(),
            creator_hash: Pubkey::new_unique().to_bytes(),
        },
        Pubkey::new_unique().to_bytes(),
    );
    let leaf_schema_event = AccountCompressionEvent::ApplicationData(ApplicationDataEvent::V1(
        ApplicationDataEventV1 {
            application_data: leaf_schema.try_to_vec().unwrap(),
        },
    ));

    // inner instruction is useless here but required by transaction parser
    let transaction_status_meta = TransactionStatusMeta {
        inner_instructions: Some(vec![InnerInstructions {
            index: 0,
            instructions: vec![
                InnerInstruction {
                    instruction: CompiledInstruction {
                        program_id_index: 2,
                        accounts: vec![],
                        data: change_log_event.try_to_vec().unwrap(),
                    },
                    stack_height: None,
                },
                InnerInstruction {
                    instruction: CompiledInstruction {
                        program_id_index: 2,
                        accounts: vec![],
                        data: leaf_schema_event.try_to_vec().unwrap(),
                    },
                    stack_height: None,
                },
            ],
        }]),
        ..Default::default()
    };

    let transaction_info =
        plerkle_serialization::solana_geyser_plugin_interface_shims::ReplicaTransactionInfoV2 {
            signature: &Signature::new_unique(),
            is_vote: false,
            transaction: &transaction,
            transaction_status_meta: &transaction_status_meta,
            index: 0,
        };
    let builder = FlatBufferBuilder::new();
    let builder = serialize_transaction(builder, &transaction_info, 10);
    let transaction_info = PlerkleTransactionInfo(
        root_as_transaction_info(builder.finished_data().to_vec().as_slice()).unwrap(),
    )
    .try_into()
    .unwrap();

    transformer
        .handle_transaction(&transaction_info)
        .await
        .unwrap();
}

fn generate_merkle_tree_from_batch_mint(batch_mint: &BatchMint) -> ConcurrentMerkleTree<10, 32> {
    let mut merkle_tree = ConcurrentMerkleTree::<10, 32>::new();
    merkle_tree.initialize().unwrap();

    for (nonce, asset) in batch_mint.batch_mints.iter().enumerate() {
        let metadata_args_hash = keccak::hashv(&[asset.mint_args.try_to_vec().unwrap().as_slice()]);
        let data_hash = keccak::hashv(&[
            &metadata_args_hash.to_bytes(),
            &asset.mint_args.seller_fee_basis_points.to_le_bytes(),
        ]);

        let creator_data = asset
            .mint_args
            .creators
            .iter()
            .map(|c| [c.address.as_ref(), &[c.verified as u8], &[c.share]].concat())
            .collect::<Vec<_>>();

        let creator_hash = keccak::hashv(
            creator_data
                .iter()
                .map(|c| c.as_slice())
                .collect::<Vec<&[u8]>>()
                .as_ref(),
        );

        let id = mpl_bubblegum::utils::get_asset_id(&batch_mint.tree_id, nonce as u64);

        let leaf = LeafSchema::V1 {
            id,
            owner: Pubkey::from_str("3VvLDXqJbw3heyRwFxv8MmurPznmDVUJS9gPMX2BDqfM").unwrap(),
            delegate: Pubkey::from_str("3VvLDXqJbw3heyRwFxv8MmurPznmDVUJS9gPMX2BDqfM").unwrap(),
            nonce: nonce as u64,
            data_hash: data_hash.to_bytes(),
            creator_hash: creator_hash.to_bytes(),
        };
        merkle_tree.append(leaf.hash()).unwrap();
    }
    merkle_tree
}

#[tokio::test]
async fn batch_mint_persister_test() {
    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new("batch_mint_persister_test".to_string()).await;
    let test_batch_mint = generate_batch_mint(10);
    let tmp_dir = tempfile::TempDir::new().unwrap();

    let tmp_file = File::create(tmp_dir.path().join("batch-mint-10.json")).unwrap();
    serde_json::to_writer(tmp_file, &test_batch_mint).unwrap();

    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = batch_mint_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        merkle_tree: Set(Pubkey::default().to_bytes().to_vec()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(0),
        batch_mint_persisting_state: Set(BatchMintPersistingState::ReceivedTransaction),
        batch_mint_fail_status: Set(None),
        collection: Set(None),
    }
    .into_active_model();

    let query = batch_mint_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([batch_mint_to_verify::Column::FileHash])
                .update_columns([batch_mint_to_verify::Column::Url])
                .update_columns([batch_mint_to_verify::Column::Signature])
                .update_columns([batch_mint_to_verify::Column::DownloadAttempts])
                .update_columns([batch_mint_to_verify::Column::BatchMintFailStatus])
                .update_columns([batch_mint_to_verify::Column::BatchMintPersistingState])
                .update_columns([batch_mint_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            let json_file =
                std::fs::read_to_string(tmp_dir.path().join("batch-mint-10.json")).unwrap();
            Ok(Box::new(serde_json::from_str(&json_file).unwrap()))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;
    let merkle_tree = generate_merkle_tree_from_batch_mint(&test_batch_mint);

    let leaf_index = 4u32;

    let payload = GetAssetProof {
        id: test_batch_mint
            .batch_mints
            .get(leaf_index as usize)
            .unwrap()
            .leaf_update
            .id()
            .to_string(),
    };
    let asset_proof = setup.das_api.get_asset_proof(payload).await.unwrap();
    let mut proofs: [[u8; 32]; 10] = [[0; 32]; 10];

    for (i, s) in asset_proof.proof.iter().enumerate() {
        proofs[i] = Pubkey::from_str(s).unwrap().to_bytes();
    }

    assert_eq!(
        merkle_tree.check_valid_proof(
            Pubkey::from_str(asset_proof.leaf.as_str())
                .unwrap()
                .to_bytes(),
            &proofs,
            leaf_index
        ),
        true
    );
    assert_eq!(
        merkle_tree.check_valid_proof(
            Pubkey::from_str(asset_proof.leaf.as_str())
                .unwrap()
                .to_bytes(),
            &proofs,
            leaf_index + 1
        ),
        false
    );

    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_persisting_state,
        BatchMintPersistingState::StoredUpdate
    );

    assert_eq!(
        batch_mint::Entity::find()
            .filter(batch_mint::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .is_some(),
        true
    );
}

#[tokio::test]
async fn batch_mint_persister_download_fail_test() {
    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new("batch_mint_persister_download_fail_test".to_string()).await;
    let test_batch_mint = generate_batch_mint(10);
    let tmp_dir = tempfile::TempDir::new().unwrap();
    let tmp_file = File::create(tmp_dir.path().join("batch-mint-10.json")).unwrap();
    serde_json::to_writer(tmp_file, &test_batch_mint).unwrap();

    let download_attempts = 0;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = batch_mint_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        merkle_tree: Set(Pubkey::default().to_bytes().to_vec()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(download_attempts),
        batch_mint_persisting_state: Set(BatchMintPersistingState::ReceivedTransaction),
        batch_mint_fail_status: Set(None),
        collection: Set(None),
    }
    .into_active_model();

    let query = batch_mint_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([batch_mint_to_verify::Column::FileHash])
                .update_columns([batch_mint_to_verify::Column::Url])
                .update_columns([batch_mint_to_verify::Column::Signature])
                .update_columns([batch_mint_to_verify::Column::DownloadAttempts])
                .update_columns([batch_mint_to_verify::Column::BatchMintFailStatus])
                .update_columns([batch_mint_to_verify::Column::BatchMintPersistingState])
                .update_columns([batch_mint_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            Err(BatchMintValidationError::Reqwest(
                "Could not download file".to_string(),
            ))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;

    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_persisting_state,
        BatchMintPersistingState::FailedToPersist
    );
    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_fail_status,
        Some(BatchMintFailStatus::DownloadFailed)
    );
}

#[tokio::test]
async fn batch_mint_with_verified_creators_test() {
    // For this test it's necessary to use Solana mainnet RPC
    let url = "https://api.mainnet-beta.solana.com".to_string();
    let solana_client = Arc::new(RpcClient::new_with_timeout(url, Duration::from_secs(3)));
    // Merkle tree created in mainnet for testing purposes
    let tree_key = Pubkey::from_str("AGMiLKtXX7PiVneM8S1KkTmCnF7X5zh6bKq4t1Mhrwpb").unwrap();

    // First we have to create offchain Merkle tree with SDK

    let batch_mint_client = BatchMintClient::new(solana_client);
    let mut batch_mint_builder = batch_mint_client
        .create_batch_mint_builder(&tree_key)
        .await
        .unwrap();

    let asset_creator = Keypair::new();
    let owner = Keypair::new();
    let delegate = Keypair::new();

    let asset = MetadataArgs {
        name: "Name".to_string(),
        symbol: "Symbol".to_string(),
        uri: "https://immutable-storage/asset/".to_string(),
        seller_fee_basis_points: 0,
        primary_sale_happened: false,
        is_mutable: false,
        edition_nonce: None,
        token_standard: Some(mpl_bubblegum::types::TokenStandard::NonFungible),
        collection: None,
        uses: None,
        token_program_version: mpl_bubblegum::types::TokenProgramVersion::Original,
        creators: vec![Creator {
            address: asset_creator.pubkey(),
            verified: true,
            share: 100,
        }],
    };

    let metadata_hash_arg = batch_mint_builder
        .add_asset(&owner.pubkey(), &delegate.pubkey(), &asset)
        .unwrap();

    let signature = asset_creator.sign_message(&metadata_hash_arg.get_message());

    let mut creators_signatures = HashMap::new();
    creators_signatures.insert(asset_creator.pubkey(), signature);

    let mut message_and_signatures = HashMap::new();
    message_and_signatures.insert(metadata_hash_arg.get_nonce(), creators_signatures);

    batch_mint_builder
        .add_signatures_for_verified_creators(message_and_signatures)
        .unwrap();

    let finalized_batch_mint = batch_mint_builder.build_batch_mint().unwrap();

    // Offchain Merkle tree creation is finished
    // Start to process it

    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new("batch_mint_with_verified_creators_test".to_string()).await;

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let tmp_file = File::create(tmp_dir.path().join("batch-mint.json")).unwrap();
    serde_json::to_writer(tmp_file, &finalized_batch_mint).unwrap();

    let download_attempts = 0;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = batch_mint_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        merkle_tree: Set(Pubkey::default().to_bytes().to_vec()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(download_attempts),
        batch_mint_persisting_state: Set(BatchMintPersistingState::ReceivedTransaction),
        batch_mint_fail_status: Set(None),
        collection: Set(None),
    }
    .into_active_model();

    let query = batch_mint_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([batch_mint_to_verify::Column::FileHash])
                .update_columns([batch_mint_to_verify::Column::Url])
                .update_columns([batch_mint_to_verify::Column::Signature])
                .update_columns([batch_mint_to_verify::Column::DownloadAttempts])
                .update_columns([batch_mint_to_verify::Column::BatchMintFailStatus])
                .update_columns([batch_mint_to_verify::Column::BatchMintPersistingState])
                .update_columns([batch_mint_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            let json_file =
                std::fs::read_to_string(tmp_dir.path().join("batch-mint.json")).unwrap();
            Ok(Box::new(serde_json::from_str(&json_file).unwrap()))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;

    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_persisting_state,
        BatchMintPersistingState::StoredUpdate
    );

    assert_eq!(
        batch_mint::Entity::find()
            .filter(batch_mint::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .is_some(),
        true
    );
}

#[tokio::test]
async fn batch_mint_with_unverified_creators_test() {
    let setup = TestSetup::new("batch_mint_with_unverified_creators_test".to_string()).await;
    // generate batch mint with creators verified value set to true
    // but signatures will not be attached
    // batch should not be saved
    let mut test_batch_mint = generate_batch_mint(10);

    // set creators verified to true for this test case
    for b_mint in test_batch_mint.batch_mints.iter_mut() {
        for creator in b_mint.mint_args.creators.iter_mut() {
            creator.verified = true;
        }
    }

    let tmp_dir = tempfile::TempDir::new().unwrap();

    let tmp_file = File::create(tmp_dir.path().join("batch-mint-10.json")).unwrap();
    serde_json::to_writer(tmp_file, &test_batch_mint).unwrap();

    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let download_attempts = 0;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = batch_mint_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        merkle_tree: Set(Pubkey::default().to_bytes().to_vec()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(download_attempts),
        batch_mint_persisting_state: Set(BatchMintPersistingState::ReceivedTransaction),
        batch_mint_fail_status: Set(None),
        collection: Set(None),
    }
    .into_active_model();

    let query = batch_mint_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([batch_mint_to_verify::Column::FileHash])
                .update_columns([batch_mint_to_verify::Column::Url])
                .update_columns([batch_mint_to_verify::Column::Signature])
                .update_columns([batch_mint_to_verify::Column::DownloadAttempts])
                .update_columns([batch_mint_to_verify::Column::BatchMintFailStatus])
                .update_columns([batch_mint_to_verify::Column::BatchMintPersistingState])
                .update_columns([batch_mint_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            let json_file =
                std::fs::read_to_string(tmp_dir.path().join("batch-mint-10.json")).unwrap();
            Ok(Box::new(serde_json::from_str(&json_file).unwrap()))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;

    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_persisting_state,
        BatchMintPersistingState::FailedToPersist
    );
}

#[tokio::test]
async fn batch_mint_with_verified_collection_test() {
    // For this test it's necessary to use Solana mainnet RPC
    let url = "https://api.mainnet-beta.solana.com".to_string();
    let solana_client = Arc::new(RpcClient::new_with_timeout(url, Duration::from_secs(3)));
    // Merkle tree created in mainnet for testing purposes
    let tree_key = Pubkey::from_str("AGMiLKtXX7PiVneM8S1KkTmCnF7X5zh6bKq4t1Mhrwpb").unwrap();

    // First we have to create offchain Merkle tree with SDK

    let batch_mint_client = BatchMintClient::new(solana_client);
    let mut batch_mint_builder = batch_mint_client
        .create_batch_mint_builder(&tree_key)
        .await
        .unwrap();

    let asset_creator = Keypair::new();
    let owner = Keypair::new();
    let delegate = Keypair::new();
    let collection_key = Pubkey::new_unique();

    let collection_config = CollectionConfig {
        collection_authority: Keypair::from_bytes(asset_creator.to_bytes().as_ref()).unwrap(),
        collection_authority_record_pda: None,
        collection_mint: collection_key,
        collection_metadata: Pubkey::new_unique(), // doesn't matter in this case
        edition_account: Pubkey::new_unique(),     // doesn't matter in this case
    };
    batch_mint_builder.setup_collection_config(collection_config);

    let asset = MetadataArgs {
        name: "Name".to_string(),
        symbol: "Symbol".to_string(),
        uri: "https://immutable-storage/asset/".to_string(),
        seller_fee_basis_points: 0,
        primary_sale_happened: false,
        is_mutable: false,
        edition_nonce: None,
        token_standard: Some(mpl_bubblegum::types::TokenStandard::NonFungible),
        collection: Some(Collection {
            verified: true,
            key: collection_key,
        }),
        uses: None,
        token_program_version: mpl_bubblegum::types::TokenProgramVersion::Original,
        creators: vec![Creator {
            address: asset_creator.pubkey(),
            verified: false,
            share: 100,
        }],
    };

    let _ = batch_mint_builder
        .add_asset(&owner.pubkey(), &delegate.pubkey(), &asset)
        .unwrap();

    let finalized_batch_mint = batch_mint_builder.build_batch_mint().unwrap();

    // Offchain Merkle tree creation is finished
    // Start to process it

    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new("batch_mint_with_verified_collection_test".to_string()).await;

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let tmp_file = File::create(tmp_dir.path().join("batch-mint.json")).unwrap();
    serde_json::to_writer(tmp_file, &finalized_batch_mint).unwrap();

    let download_attempts = 0;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = batch_mint_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        merkle_tree: Set(Pubkey::default().to_bytes().to_vec()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(download_attempts),
        batch_mint_persisting_state: Set(BatchMintPersistingState::ReceivedTransaction),
        batch_mint_fail_status: Set(None),
        collection: Set(Some(collection_key.to_bytes().to_vec())),
    }
    .into_active_model();

    let query = batch_mint_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([batch_mint_to_verify::Column::FileHash])
                .update_columns([batch_mint_to_verify::Column::Url])
                .update_columns([batch_mint_to_verify::Column::Signature])
                .update_columns([batch_mint_to_verify::Column::DownloadAttempts])
                .update_columns([batch_mint_to_verify::Column::BatchMintFailStatus])
                .update_columns([batch_mint_to_verify::Column::BatchMintPersistingState])
                .update_columns([batch_mint_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            let json_file =
                std::fs::read_to_string(tmp_dir.path().join("batch-mint.json")).unwrap();
            Ok(Box::new(serde_json::from_str(&json_file).unwrap()))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;

    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_persisting_state,
        BatchMintPersistingState::StoredUpdate
    );

    assert_eq!(
        batch_mint::Entity::find()
            .filter(batch_mint::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .is_some(),
        true
    );
}

#[tokio::test]
async fn batch_mint_with_wrong_collection_test() {
    // For this test it's necessary to use Solana mainnet RPC
    let url = "https://api.mainnet-beta.solana.com".to_string();
    let solana_client = Arc::new(RpcClient::new_with_timeout(url, Duration::from_secs(3)));
    // Merkle tree created in mainnet for testing purposes
    let tree_key = Pubkey::from_str("AGMiLKtXX7PiVneM8S1KkTmCnF7X5zh6bKq4t1Mhrwpb").unwrap();

    // First we have to create offchain Merkle tree with SDK

    let batch_mint_client = BatchMintClient::new(solana_client);
    let mut batch_mint_builder = batch_mint_client
        .create_batch_mint_builder(&tree_key)
        .await
        .unwrap();

    let asset_creator = Keypair::new();
    let owner = Keypair::new();
    let delegate = Keypair::new();
    let collection_key = Pubkey::new_unique();

    let wrong_collection_key = Pubkey::new_unique();

    let collection_config = CollectionConfig {
        collection_authority: Keypair::from_bytes(asset_creator.to_bytes().as_ref()).unwrap(),
        collection_authority_record_pda: None,
        collection_mint: collection_key,
        collection_metadata: Pubkey::new_unique(), // doesn't matter in this case
        edition_account: Pubkey::new_unique(),     // doesn't matter in this case
    };
    batch_mint_builder.setup_collection_config(collection_config);

    let asset = MetadataArgs {
        name: "Name".to_string(),
        symbol: "Symbol".to_string(),
        uri: "https://immutable-storage/asset/".to_string(),
        seller_fee_basis_points: 0,
        primary_sale_happened: false,
        is_mutable: false,
        edition_nonce: None,
        token_standard: Some(mpl_bubblegum::types::TokenStandard::NonFungible),
        collection: Some(Collection {
            verified: true,
            key: collection_key,
        }),
        uses: None,
        token_program_version: mpl_bubblegum::types::TokenProgramVersion::Original,
        creators: vec![Creator {
            address: asset_creator.pubkey(),
            verified: false,
            share: 100,
        }],
    };

    let _ = batch_mint_builder
        .add_asset(&owner.pubkey(), &delegate.pubkey(), &asset)
        .unwrap();

    let finalized_batch_mint = batch_mint_builder.build_batch_mint().unwrap();

    // Offchain Merkle tree creation is finished
    // Start to process it

    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new("batch_mint_with_verified_collection_test".to_string()).await;

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let tmp_file = File::create(tmp_dir.path().join("batch-mint.json")).unwrap();
    serde_json::to_writer(tmp_file, &finalized_batch_mint).unwrap();

    let download_attempts = 0;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = batch_mint_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        merkle_tree: Set(Pubkey::default().to_bytes().to_vec()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(download_attempts),
        batch_mint_persisting_state: Set(BatchMintPersistingState::ReceivedTransaction),
        batch_mint_fail_status: Set(None),
        collection: Set(Some(wrong_collection_key.to_bytes().to_vec())),
    }
    .into_active_model();

    let query = batch_mint_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([batch_mint_to_verify::Column::FileHash])
                .update_columns([batch_mint_to_verify::Column::Url])
                .update_columns([batch_mint_to_verify::Column::Signature])
                .update_columns([batch_mint_to_verify::Column::DownloadAttempts])
                .update_columns([batch_mint_to_verify::Column::BatchMintFailStatus])
                .update_columns([batch_mint_to_verify::Column::BatchMintPersistingState])
                .update_columns([batch_mint_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            let json_file =
                std::fs::read_to_string(tmp_dir.path().join("batch-mint.json")).unwrap();
            Ok(Box::new(serde_json::from_str(&json_file).unwrap()))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;

    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_persisting_state,
        BatchMintPersistingState::FailedToPersist
    );
}

#[tokio::test]
async fn batch_mint_with_unverified_collection_test() {
    // For this test it's necessary to use Solana mainnet RPC
    let url = "https://api.mainnet-beta.solana.com".to_string();
    let solana_client = Arc::new(RpcClient::new_with_timeout(url, Duration::from_secs(3)));
    // Merkle tree created in mainnet for testing purposes
    let tree_key = Pubkey::from_str("AGMiLKtXX7PiVneM8S1KkTmCnF7X5zh6bKq4t1Mhrwpb").unwrap();

    // First we have to create offchain Merkle tree with SDK

    let batch_mint_client = BatchMintClient::new(solana_client);
    let mut batch_mint_builder = batch_mint_client
        .create_batch_mint_builder(&tree_key)
        .await
        .unwrap();

    let asset_creator = Keypair::new();
    let owner = Keypair::new();
    let delegate = Keypair::new();
    let collection_key = Pubkey::new_unique();

    let collection_config = CollectionConfig {
        collection_authority: Keypair::from_bytes(asset_creator.to_bytes().as_ref()).unwrap(),
        collection_authority_record_pda: None,
        collection_mint: collection_key,
        collection_metadata: Pubkey::new_unique(), // doesn't matter in this case
        edition_account: Pubkey::new_unique(),     // doesn't matter in this case
    };
    batch_mint_builder.setup_collection_config(collection_config);

    let asset = MetadataArgs {
        name: "Name".to_string(),
        symbol: "Symbol".to_string(),
        uri: "https://immutable-storage/asset/".to_string(),
        seller_fee_basis_points: 0,
        primary_sale_happened: false,
        is_mutable: false,
        edition_nonce: None,
        token_standard: Some(mpl_bubblegum::types::TokenStandard::NonFungible),
        collection: Some(Collection {
            verified: true,
            key: collection_key,
        }),
        uses: None,
        token_program_version: mpl_bubblegum::types::TokenProgramVersion::Original,
        creators: vec![Creator {
            address: asset_creator.pubkey(),
            verified: false,
            share: 100,
        }],
    };

    let _ = batch_mint_builder
        .add_asset(&owner.pubkey(), &delegate.pubkey(), &asset)
        .unwrap();

    let finalized_batch_mint = batch_mint_builder.build_batch_mint().unwrap();

    // Offchain Merkle tree creation is finished
    // Start to process it

    let client = StatsdClient::builder("batch_mint.test", NopMetricSink)
        .with_error_handler(|e| eprintln!("metric error: {}", e))
        .build();

    set_global_default(client);

    let setup = TestSetup::new("batch_mint_with_verified_collection_test".to_string()).await;

    let tmp_dir = tempfile::TempDir::new().unwrap();
    let tmp_file = File::create(tmp_dir.path().join("batch-mint.json")).unwrap();
    serde_json::to_writer(tmp_file, &finalized_batch_mint).unwrap();

    let download_attempts = 0;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = batch_mint_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        merkle_tree: Set(Pubkey::default().to_bytes().to_vec()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(download_attempts),
        batch_mint_persisting_state: Set(BatchMintPersistingState::ReceivedTransaction),
        batch_mint_fail_status: Set(None),
        collection: Set(None),
    }
    .into_active_model();

    let query = batch_mint_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([batch_mint_to_verify::Column::FileHash])
                .update_columns([batch_mint_to_verify::Column::Url])
                .update_columns([batch_mint_to_verify::Column::Signature])
                .update_columns([batch_mint_to_verify::Column::DownloadAttempts])
                .update_columns([batch_mint_to_verify::Column::BatchMintFailStatus])
                .update_columns([batch_mint_to_verify::Column::BatchMintPersistingState])
                .update_columns([batch_mint_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            let json_file =
                std::fs::read_to_string(tmp_dir.path().join("batch-mint.json")).unwrap();
            Ok(Box::new(serde_json::from_str(&json_file).unwrap()))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;

    assert_eq!(
        batch_mint_to_verify::Entity::find()
            .filter(batch_mint_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .batch_mint_persisting_state,
        BatchMintPersistingState::FailedToPersist
    );
}
