use crate::common::TestSetup;
use borsh::BorshSerialize;
use das_api::api::ApiContract;
use das_api::api::GetAssetProof;
use digital_asset_types::dao::sea_orm_active_enums::{RollupFailStatus, RollupPersistingState};
use digital_asset_types::dao::{rollup, rollup_to_verify};
use flatbuffers::FlatBufferBuilder;
use mpl_bubblegum::types::LeafSchema;
use nft_ingester::batch_mint_updates::create_batch_mint_notification_channel;
use nft_ingester::plerkle::PlerkleTransactionInfo;
use plerkle_serialization::root_as_transaction_info;
use plerkle_serialization::serializer::serialize_transaction;
use program_transformers::batch_minting::batch_mint_persister::{
    BatchMint, BatchMintPersister, MockBatchMintDownloader,
};
use program_transformers::batch_minting::tests::generate_batch_mint;
use program_transformers::error::BatchMintValidationError;
use sea_orm::sea_query::OnConflict;
use sea_orm::{ColumnTrait, ConnectionTrait, DbBackend, IntoActiveModel, QueryTrait, Set};
use sea_orm::{EntityTrait, QueryFilter};
use solana_sdk::instruction::CompiledInstruction;
use solana_sdk::keccak;
use solana_sdk::message::{Message, MessageHeader};
use solana_sdk::pubkey::Pubkey;
use solana_sdk::signature::Signature;
use solana_sdk::transaction::{SanitizedTransaction, Transaction};
use solana_transaction_status::{InnerInstruction, InnerInstructions, TransactionStatusMeta};
use spl_concurrent_merkle_tree::concurrent_merkle_tree::ConcurrentMerkleTree;
use std::fs::File;
use std::str::FromStr;
use tokio::task::JoinSet;

#[tokio::test]
async fn save_batch_mint_to_queue_test() {
    let setup = TestSetup::new("save_batch_mint_to_queue_test".to_string()).await;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();

    // arbitrary data
    let batch_mint_instruction_data =
        mpl_bubblegum::instructions::FinalizeTreeWithRootInstructionArgs {
            rightmost_root: [1; 32],
            rightmost_leaf: [1; 32],
            rightmost_index: 99,
            metadata_url: metadata_url.clone(),
            metadata_hash: metadata_hash.clone(),
        };

    // took it from Bubblegum client
    // this value is generated by Anchor library, it's instruction identifier
    let mut instruction_data = vec![101, 214, 253, 135, 176, 170, 11, 235];
    instruction_data.extend(batch_mint_instruction_data.try_to_vec().unwrap().iter());

    let transaction = SanitizedTransaction::from_transaction_for_tests(Transaction {
        signatures: vec![Signature::new_unique()],
        message: Message {
            header: MessageHeader {
                num_required_signatures: 1,
                num_readonly_signed_accounts: 0,
                num_readonly_unsigned_accounts: 0,
            },
            account_keys: vec![
                Pubkey::new_unique(),
                Pubkey::from_str("BGUMAp9Gq7iTEuizy4pqaxsTyUCBK68MDfK752saRPUY").unwrap(),
                Pubkey::new_unique(),
                Pubkey::new_unique(),
            ],
            recent_blockhash: [1; 32].into(),
            instructions: vec![CompiledInstruction {
                program_id_index: 1,
                accounts: vec![2, 3],
                data: instruction_data,
            }],
        },
    });

    // inner instruction is useless here but required by transaction parser
    let transaction_status_meta = TransactionStatusMeta {
        inner_instructions: Some(vec![InnerInstructions {
            index: 0,
            instructions: vec![InnerInstruction {
                instruction: CompiledInstruction {
                    program_id_index: 2,
                    accounts: vec![],
                    data: vec![],
                },
                stack_height: None,
            }],
        }]),
        ..Default::default()
    };

    let transaction_info =
        plerkle_serialization::solana_geyser_plugin_interface_shims::ReplicaTransactionInfoV2 {
            signature: &Signature::new_unique(),
            is_vote: false,
            transaction: &transaction,
            transaction_status_meta: &transaction_status_meta,
            index: 0,
        };
    let builder = FlatBufferBuilder::new();
    let builder = serialize_transaction(builder, &transaction_info, 10);
    let transaction_info = PlerkleTransactionInfo(
        root_as_transaction_info(builder.finished_data().to_vec().as_slice()).unwrap(),
    )
    .try_into()
    .unwrap();

    setup
        .transformer
        .handle_transaction(&transaction_info)
        .await
        .unwrap();

    let r = rollup_to_verify::Entity::find()
        .filter(rollup_to_verify::Column::FileHash.eq(metadata_hash.clone()))
        .one(setup.db.as_ref())
        .await
        .unwrap()
        .unwrap();

    assert_eq!(r.file_hash, metadata_hash);
    assert_eq!(r.url, metadata_url);
}

fn generate_merkle_tree_from_batch_mint(batch_mint: &BatchMint) -> ConcurrentMerkleTree<10, 32> {
    let mut merkle_tree = ConcurrentMerkleTree::<10, 32>::new();
    merkle_tree.initialize().unwrap();

    for (nonce, asset) in batch_mint.batch_mints.iter().enumerate() {
        let metadata_args_hash = keccak::hashv(&[asset.mint_args.try_to_vec().unwrap().as_slice()]);
        let data_hash = keccak::hashv(&[
            &metadata_args_hash.to_bytes(),
            &asset.mint_args.seller_fee_basis_points.to_le_bytes(),
        ]);

        let creator_data = asset
            .mint_args
            .creators
            .iter()
            .map(|c| [c.address.as_ref(), &[c.verified as u8], &[c.share]].concat())
            .collect::<Vec<_>>();

        let creator_hash = keccak::hashv(
            creator_data
                .iter()
                .map(|c| c.as_slice())
                .collect::<Vec<&[u8]>>()
                .as_ref(),
        );

        let id = mpl_bubblegum::utils::get_asset_id(&batch_mint.tree_id, nonce as u64);

        let leaf = LeafSchema::V1 {
            id,
            owner: Pubkey::from_str("3VvLDXqJbw3heyRwFxv8MmurPznmDVUJS9gPMX2BDqfM").unwrap(),
            delegate: Pubkey::from_str("3VvLDXqJbw3heyRwFxv8MmurPznmDVUJS9gPMX2BDqfM").unwrap(),
            nonce: nonce as u64,
            data_hash: data_hash.to_bytes(),
            creator_hash: creator_hash.to_bytes(),
        };
        merkle_tree.append(leaf.hash()).unwrap();
    }
    merkle_tree
}

#[tokio::test]
async fn batch_mint_persister_test() {
    let setup = TestSetup::new("batch_mint_persister_test".to_string()).await;
    let test_batch_mint = generate_batch_mint(10);
    let tmp_dir = tempfile::TempDir::new().unwrap();

    let tmp_file = File::create(tmp_dir.path().join("batch-mint-10.json")).unwrap();
    serde_json::to_writer(tmp_file, &test_batch_mint).unwrap();

    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = rollup_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(0),
        rollup_persisting_state: Set(RollupPersistingState::ReceivedTransaction),
        rollup_fail_status: Set(None),
    }
    .into_active_model();

    let query = rollup_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([rollup_to_verify::Column::FileHash])
                .update_columns([rollup_to_verify::Column::Url])
                .update_columns([rollup_to_verify::Column::Signature])
                .update_columns([rollup_to_verify::Column::DownloadAttempts])
                .update_columns([rollup_to_verify::Column::RollupFailStatus])
                .update_columns([rollup_to_verify::Column::RollupPersistingState])
                .update_columns([rollup_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            let json_file =
                std::fs::read_to_string(tmp_dir.path().join("batch-mint-10.json")).unwrap();
            Ok(Box::new(serde_json::from_str(&json_file).unwrap()))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;
    let merkle_tree = generate_merkle_tree_from_batch_mint(&test_batch_mint);

    let leaf_index = 4u32;

    let payload = GetAssetProof {
        id: test_batch_mint
            .batch_mints
            .get(leaf_index as usize)
            .unwrap()
            .leaf_update
            .id()
            .to_string(),
    };
    let asset_proof = setup.das_api.get_asset_proof(payload).await.unwrap();
    let mut proofs: [[u8; 32]; 10] = [[0; 32]; 10];

    for (i, s) in asset_proof.proof.iter().enumerate() {
        proofs[i] = Pubkey::from_str(s).unwrap().to_bytes();
    }

    assert_eq!(
        merkle_tree.check_valid_proof(
            Pubkey::from_str(asset_proof.leaf.as_str())
                .unwrap()
                .to_bytes(),
            &proofs,
            leaf_index
        ),
        true
    );
    assert_eq!(
        merkle_tree.check_valid_proof(
            Pubkey::from_str(asset_proof.leaf.as_str())
                .unwrap()
                .to_bytes(),
            &proofs,
            leaf_index + 1
        ),
        false
    );

    assert_eq!(
        rollup_to_verify::Entity::find()
            .filter(rollup_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .rollup_persisting_state,
        RollupPersistingState::StoredUpdate
    );

    assert_eq!(
        rollup::Entity::find()
            .filter(rollup::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .is_some(),
        true
    );
}

#[tokio::test]
async fn batch_mint_persister_download_fail_test() {
    let setup = TestSetup::new("batch_mint_persister_download_fail_test".to_string()).await;
    let test_batch_mint = generate_batch_mint(10);
    let tmp_dir = tempfile::TempDir::new().unwrap();
    let tmp_file = File::create(tmp_dir.path().join("batch-mint-10.json")).unwrap();
    serde_json::to_writer(tmp_file, &test_batch_mint).unwrap();

    let download_attempts = 0;
    let metadata_url = "url".to_string();
    let metadata_hash = "hash".to_string();
    let batch_mint_to_verify = rollup_to_verify::ActiveModel {
        file_hash: Set(metadata_hash.clone()),
        url: Set(metadata_url.clone()),
        created_at_slot: Set(10),
        signature: Set(Signature::new_unique().to_string()),
        staker: Set(Pubkey::default().to_bytes().to_vec()),
        download_attempts: Set(download_attempts),
        rollup_persisting_state: Set(RollupPersistingState::ReceivedTransaction),
        rollup_fail_status: Set(None),
    }
    .into_active_model();

    let query = rollup_to_verify::Entity::insert(batch_mint_to_verify)
        .on_conflict(
            OnConflict::columns([rollup_to_verify::Column::FileHash])
                .update_columns([rollup_to_verify::Column::Url])
                .update_columns([rollup_to_verify::Column::Signature])
                .update_columns([rollup_to_verify::Column::DownloadAttempts])
                .update_columns([rollup_to_verify::Column::RollupFailStatus])
                .update_columns([rollup_to_verify::Column::RollupPersistingState])
                .update_columns([rollup_to_verify::Column::CreatedAtSlot])
                .to_owned(),
        )
        .build(DbBackend::Postgres);
    setup.db.execute(query).await.unwrap();

    let mut mocked_downloader = MockBatchMintDownloader::new();
    mocked_downloader
        .expect_download_batch_mint_and_check_checksum()
        .returning(move |_, _| {
            Err(BatchMintValidationError::Reqwest(
                "Could not download file".to_string(),
            ))
        });

    let mut tasks = JoinSet::new();
    let r = create_batch_mint_notification_channel(&setup.database_test_url, &mut tasks)
        .await
        .unwrap();
    let batch_mint_persister = BatchMintPersister::new(setup.db.clone(), r, mocked_downloader);
    let (batch_mint_to_verify, _) = batch_mint_persister
        .get_batch_mint_to_verify()
        .await
        .unwrap();
    batch_mint_persister
        .persist_batch_mint(batch_mint_to_verify.unwrap(), None)
        .await;

    assert_eq!(
        rollup_to_verify::Entity::find()
            .filter(rollup_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .rollup_persisting_state,
        RollupPersistingState::FailedToPersist
    );
    assert_eq!(
        rollup_to_verify::Entity::find()
            .filter(rollup_to_verify::Column::FileHash.eq(metadata_hash.clone()))
            .one(setup.db.as_ref())
            .await
            .unwrap()
            .unwrap()
            .rollup_fail_status,
        Some(RollupFailStatus::DownloadFailed)
    );
}
